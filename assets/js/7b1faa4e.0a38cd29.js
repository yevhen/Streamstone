"use strict";(self.webpackChunkdocs_site=self.webpackChunkdocs_site||[]).push([[22],{5817:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"scenarios/S10_Stream_directory","title":"Implementing a Stream Directory","description":"This scenario demonstrates how to implement a stream directory in Streamstone.","source":"@site/docs/scenarios/S10_Stream_directory.md","sourceDirName":"scenarios","slug":"/scenarios/S10_Stream_directory","permalink":"/Streamstone/docs/scenarios/S10_Stream_directory","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Handling Duplicate Events","permalink":"/Streamstone/docs/scenarios/S09_Handling_duplicates"},"next":{"title":"Sharding Streams","permalink":"/Streamstone/docs/scenarios/S11_Sharding_streams"}}');var r=n(4848),a=n(8453);const s={},o="Implementing a Stream Directory",l={},c=[];function m(e){const t={code:"code",h1:"h1",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"implementing-a-stream-directory",children:"Implementing a Stream Directory"})}),"\n",(0,r.jsx)(t.p,{children:"This scenario demonstrates how to implement a stream directory in Streamstone."}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",metastring:'title="S10_Stream_directory.cs"',children:'using Azure;\n\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Threading.Tasks;\n\nusing Azure.Data.Tables;\n\nusing Streamstone;\nusing Streamstone.Utility;\n\n\nnamespace Example.Scenarios\n{\n    public class S10_Stream_directory : Scenario\n    {\n        public override async Task RunAsync()\n        {\n            await MultipleStreamsPerPartitionUsingStreamProperties();\n            await MultipleStreamsPerPartitionUsingProjection();\n            await SingleStreamPerPartitionUsingIndirectionLayer();\n        }\n\n        /// <summary>\n        /// This the simplest approach. You just need to create an additional stream metadata column and then you can simply query on it.\n        /// \n        /// It\'s also the slowest approach of all, since all rows in a partition need to scanned. Still, it should \n        /// perform quite well for majority of apps as there won\'t be too many rows in a single physical partition.\n        /// </summary>\n        async Task MultipleStreamsPerPartitionUsingStreamProperties()\n        {\n            var properties = StreamProperties.From(new { RowType = "STREAM" });\n\n            await Stream.ProvisionAsync(VirtualPartition("11"), properties);\n            await Stream.ProvisionAsync(VirtualPartition("22"), properties);\n\n            // the below code will scan all rows in a single physical partition\n            // also, if there more than 1000 streams (header rows), pagination need to be utilized as per regular ATS limits\n\n            var filter = TableClient.CreateQueryFilter($"PartitionKey eq {Partition.PartitionKey} and {nameof(StreamHeaderEntity.RowType)} eq STREAM");\n\n            var count = Partition.Table\n                .ExecuteQuery<StreamHeaderEntity>(filter)\n                .Count();\n\n            Console.WriteLine(count);\n        }\n\n        /// <summary>\n        /// This approach is a bit more complex, since you will need to track the start of lifecycle of the stream and include projection of its header. \n        /// The projection row will be simply a reverse rowkey of stream header entity, so that you can query a range of rows using prefix query.\n        /// \n        /// This is the most performant way to query all streams(headers) in a single physical partition.  There is no any other approach which is more \n        /// performant than this one.  The only downside, it could only be used along with Stream.WriteAsync since at the moment Streamstone doesn\'t support \n        /// inclusion of additional entities when provisioning streams.\n        /// </summary>\n        async Task MultipleStreamsPerPartitionUsingProjection()\n        {\n            await Stream.WriteAsync(\n                new Stream(VirtualPartition("sid-33")),\n                Event(Include.Insert(new StreamHeaderEntity("sid-33"))));\n\n            await Stream.WriteAsync(\n                new Stream(VirtualPartition("sid-44")),\n                Event(Include.Insert(new StreamHeaderEntity("sid-44"))));\n\n            // the below code will scan only a limited range of rows in a single physical partition\n            // also, if there more than 1000 streams (header rows), pagination need to be utilized as per regular ATS limits\n\n            var count = Partition\n                .RowKeyPrefixQuery<TableEntity>(StreamHeaderEntity.Prefix)\n                .ToList()\n                .Count;\n\n            Console.WriteLine(count);\n        }\n\n        /// <summary>\n        /// For this way you may simply create a facade through which all stream operations will go. Behind the curtain, you will record (track) all \n        /// created streams in some dedicated partition, so that you can simply query single partition to get information about all streams in your \n        /// system. Basically, it\'s a just an implementation of multi-tenancy.\n        ///\n        /// This last approach is little bit more involved but with stream-per-partition it is the only possible approach.  There will be some additional \n        /// complexity related to maintaining consistency between directory partition and actual stream partition, since there is no cross-partition \n        /// transactions in WATS.  But that should be a really rare case (failure to write stream after recording it in directory) and can be resolved \n        /// with manual intervention.\n        /// </summary>\n        async Task SingleStreamPerPartitionUsingIndirectionLayer()\n        {\n            var store = new EventStore(new Partition(Table, "DIR"));\n\n            await store.ProvisionAsync(VirtualPartition("vs-111"));\n            await store.ProvisionAsync(VirtualPartition("vs-222"));\n\n            await store.WriteAsync(new Stream(new Partition(Partition.Table, "ps-333")), Event());\n            await store.WriteAsync(new Stream(new Partition(Partition.Table, "ps-444")), Event());\n\n            var count = store.Streams().Count();\n            Console.WriteLine(count);\n        }\n\n        Partition VirtualPartition(string stream)\n        {\n            return new Partition(Partition.Table, Partition.PartitionKey + "|" + stream);\n        }\n\n        class StreamHeaderEntity : ITableEntity\n        {\n            public const string Prefix = "STREAM|";\n\n            public StreamHeaderEntity()\n            { }\n\n            public StreamHeaderEntity(string id)\n            {\n                RowKey = Prefix + id;\n            }\n\n            public string PartitionKey { get; set; }\n\n            public string RowKey { get; set; }\n\n            public DateTimeOffset? Timestamp { get; set; }\n\n            public ETag ETag { get; set; }\n\n            public string RowType { get; set; }\n        }\n\n        static EventData Event(params Include[] includes)\n        {\n            return new EventData(EventId.None, EventIncludes.From(includes));\n        }\n\n        class EventStore\n        {\n            readonly Partition directory;\n\n            public EventStore(Partition directory)\n            {\n                this.directory = directory;\n                this.directory.Table.CreateIfNotExistsAsync().Wait();\n            }\n\n            public async Task<Stream> ProvisionAsync(Partition partition)\n            {\n                await Record(partition);\n                return await Stream.ProvisionAsync(partition);\n            }\n\n            public async Task<StreamWriteResult> WriteAsync(Stream stream, params EventData[] events)\n            {\n                if (stream.IsTransient)\n                    await Record(stream.Partition);\n\n                return await Stream.WriteAsync(stream, events);\n            }\n\n            Task Record(Partition partition)\n            {\n                var header = new TableEntity(directory.PartitionKey, partition.ToString());\n                return directory.Table.AddEntityAsync(header);\n            }\n\n            public IEnumerable<string> Streams()\n            {\n                // NOTE: if there more than 1000 streams (header rows) in directory,\n                //       pagination need to be implemented as per regular ATS limits\n                var filter = TableClient.CreateQueryFilter($"PartitionKey eq {directory.PartitionKey}");\n                return directory.Table.ExecuteQuery<TableEntity>(filter)\n                                .Select(x => x.RowKey);\n            }\n        }\n    }\n}\n'})})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>o});var i=n(6540);const r={},a=i.createContext(r);function s(e){const t=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(a.Provider,{value:t},e.children)}}}]);